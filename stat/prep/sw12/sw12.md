# Zeitreihen

> Beispiel: Argumente für Reduzierung der Treibhausgase hängen aus einer Kombination von Wissenschaft, Wirtschaft und **Zeitreihenanalyse** zusammen

*  zeitabhängige Folge von Datenpunkten 
* sagt nichts über Gründe für Daten



## Trend

> Passagierdaten steigen jährlich

* allmähliche Änderung des Mittelwertes der Zeitreihe



## Saisonalität

> In Ferienzeit wurde mehr geflogen als sonst

* Schwankungen innerhalb eines Jahres
* periodische Muster



## serielle Korrelation

* Beobachtungen sind **nicht** unabhängig voneinander
* Benachbarte Werte sind ähnlich
* Beispiele:
  * Temperatur, Druck, akkustische Emissionen, Aktienpreise, Verschmutzung, Niederschläge, Einkommen, Anzahl Unfälle
  * überall wo keine schlagartige Änderungen von Werten vorkommen



## Ziele von Zeitreihen

* **Deskriptive Analyse**: grundsätzliche Eigenschaften verstehen mit Übersichtsstatistiken / Visualisierungen
* **Modellierung und Interpretation**: Modellierung des der Zeitreihe zu Grunde liegenden Prozesses für tieferes Verständnis
* **Zerlegung**: Unterteilung in
  * Saisonalität
  * Trend
* **Vorhersage**: zukünftige Werte einer Zeitreihe vorhersagen
* **Regression**: Zeitreihe durch mehrere andere Zeitreihen erklären



## Korrelation / kausale Zusammenhänge zwischen Zeitreihen

* Mit Vergleich von verschiedenen Zeitreihen können Aussagen gemacht werden über
  * Korrelation
  * **nicht** aber über kausale Zusammenhänge



## log-return

<p style="color:#50b4d8">TODO: better explanation why this is relevant</p>

* Näherung der relativen Änderung (in Prozent) bezüglich vorhergehenden Werten
* Vorhersagen des log-returns beruhend aus historischen Daten unmöglich



## Zeitreihe plotten

- `pd.DatetimeIndex(column)` 

- `data.set_index(column, inplace=True)` 

  $$\to$$ `inplace=True` , damit Datensatz verändert wird



```python
import matplotlib.pyplot as plt 
import pandas as pd

data["TravelDate"] = pd.DatetimeIndex(data["TravelDate"]) 
data.set_index("TravelDate", inplace=True)

data.plot()
plt.xlabel("Reisedatum") 
plt.ylabel("Anzahl Passagiere (in 1000)")
```



## Teilmenge einer Zeitreihe plotten

- z.B. nur australischen Sommer betrachten
- Auf Zeitspanne fokussieren, 
- um Verhalten der Daten in grösserem Detail anzusehen
- `data.loc[]`



```python
data.loc["1980-9":"1990-3", :].plot()
```



## Multivariate Zeitreihen plotten

* Zeitreihen miteinander vergleichen
* `data.copy()`
* `data1[new_column] = data2[column_to_compare]`
* `data.plot(subplots=True)`



```python
import pandas as pd

# Erster Datensatz kopieren, 
# um originale Daten nicht zu verändern
data1 = data.copy()

# Datensatz um Spalte erweitern
data1["kilowatt"] = data2["kilowatt"] 

data1["Quarter"] = pd.DatetimeIndex(data["Quarter"])
data1.set_index("Quarter", inplace=True)
data.plot(subplots=True)
```



## Analyse Zeitreihenvergleich

<p style="color:#50b4d8">TODO: better example?</p>

* mögliche Fragen:
  * sind saisonale Effekte über Zeitraum stabil?
  * kann also die Varianz als konstant betrachted werden?
  * ist ein Muster im Restteil erkennbar?
  * benötigt es also eine Transformation? (nur falls Muster erkennbar)
  * ist ein Trend erkennbar?
* Beispiel megalitres und kilowatt:
  * beide Grössen zeigen wachsenden Trend
  * Annahme: teilweise wegen steigender Bevölkerung über gleiche Periode
  * Jedoch nahm Kilowatt um Faktor 7 zu, während Bevölkerung sich nur knapp verdoppelt hat (diese Aussage nur mit zusätzlichen Daten möglich)

![Screen Shot 2019-02-20 at 08.46.53](/Users/christopher/Development/studies/github/summaries-me/stat/prep/sw12/images/analysis.png)



## Datentransformation

* oft wünschenswert / notwendig vor Anwendung auf Modelle oder Vorhersagen
* viele Methoden erwarten:
  * symmetrische oder normale Verteilung
  * linearer Trend zwischen Daten und Zeit
  * zeitlich konstante Varianz



## Box-Cox-Transformation

* Familie von Transformationen, um Schiefe und Varianz zu korrigieren / stabilisieren
* Für eine Zeitreihe mit positiven Werten $$\{x_1, x_2, …\}$$ sind Box-Cox-Transformationen definiert durch:
  
  * $$\displaystyle g(x) = \begin{cases} \frac{x^\lambda - 1}{\lambda} & \quad \text{if }  \lambda \neq 0 \\ log(x) & \quad \text{if } \lambda = 0 \end{cases}$$



* Ziel: Parameter $$\lambda$$ so wählen, dass gewünschte Eigenschaften erfüllt sind
* Kommt einer Modifikation der Werte gleich!



## Box-Cox-Transformation anwenden

* Eigene `boxcox(x, lambd)` Funktion definieren
* Funktion auf Werte anwenden (nicht Zeit)



```python
def boxcox(x, lambd):
	return np.log(x) if (lambd==0) else (x**lambd-1)/lambd

data["transformed_2"] = boxcox(data["values"], 2)
data["transformed_2"].plot()
```



## Zeitachsentransformation

* Manchmal notwendig Zeitachse zu transformieren
* z.B. Zeitverschiebung oder shifting
* time-shift
* Zeitverschiebung durch einen $$lag$$ von $$k \in \Z$$ definiert durch: 
  $$g(x_i) = x_{i-k}$$
* Für Spezialfall $$k = 1$$ heisst Zeitverschiebung $$backshift$$ 
  $$B(x_i) = x_{i-1}$$



## Zeitachsentransformation anwenden

* `data[values].shift(5)`
* backshift: `shift(1)`



```python
data["shifted_4"] = data["original"].shift(4)

data["original"].plot()
data["shifted_4"].plot()
plt.legend(["Original Data", "Shifted Data"])
plt.show()
```



## Log-Returns

* Rückwärtszeitverschiebung angewendet, falls Differenzen von Zeitreihen berechnet werden: $$x_i - x_{i-1} = x_i - B(x_i)$$
* Oft Differenzen mit Box-Cox-Transformationen kombinieren



## Log-Returns Beispiel

* z.B. um den **relativen Zuwachs** der Werte zu vergleichen (Aufgabe 12.1e )
* log-returns einer (finanziellen) Zeitreihe sind definiert durch
  
  * $$\displaystyle y_i = log(x_i) - log(x_{i-1}) \approx \frac{x_i - x_{i-1}}{x_{i-1}}$$



* D.h. log-return Zeitreihe $$y_i​$$ nähert den relativen Zuwachs der Zeitreihe $$x_i​$$ zu jedem Zeitpunkt an
* oft für finanzielle Anwendungen studiert:
  * $$\{x_1, x_2, …\}$$ hat vielleicht offensichtliches Muster
  * $$\{y_1, y_2, … \}$$ aber oft sehr zufällig
* Analysten versuchen Wartezeit zwischen Fluktuationen zu modellieren



## Visualisierung

* Wichtigster Teil der deskriptiven Statistik
* Zeitreihenplot: normalerweise erster Schritt der Analyse von Zeitreihen
* Interpretierbarkeit hängt stark von 
  * Anzahl und
  * Glattheit der Daten ab



## Fehler aus Daten entfernen

* mit Filter
* z.B. falsche/unmögliche Werte wegen Sensorfehler ausfiltern

```python
Temperatur = Temperatur[Temperatur["°C"] > -200]
```



## Boxplot von Zeitreihen über $$x$$ Tage

* Beispiel: Daten für jede Stunde über 20 Tage
* `data.boxplot("values", by="column")`



```python
data = data.loc["2004-3-10":"2004-3-30", "values"]
data.boxplot("values", by="Time")

plt.xticks(rotation=45)
plt.show()
```



## Lagged Scatterplot

* Scatterplot für 
  * graphische Visualisierung 
  * für die Korrelation
  * von aufeinanderfolgenden Beobachtungen
* ursprüngliche Zeitreihe gegen zeitverschobene Zeitreihe aufgezeichnet
* z.B. Korrelation zwischen benachbarten stündlichen Temperaturen
* z.B. Korrelation zwischen benachbarten 10-stündlichen Temperaturen



## Lagged Scatterplot anwenden

* `lag_plot(data, hourly_step)`



```python
from pandas.plotting import lag_plot

# Korrelation von Daten, die 10 Stunden auseinander liegen
lag_plot(data, 10)
```



## Zerlegung von Zeitreihen

* Unterteilung in Trend und Saisonalität
* Trend und saisonale Effekte abschätzen



## Additives Zerlegungsmodell

- Einfaches **additives** Zerlegungsmodell gegeben durch:
  
  

  - $$x_k = m_k + s_k + z_k$$

  

- $$k$$ : Zeitindex

- $$x_k$$ : beobachtete Daten

- $$m_k$$ : Trend

- $$s_k$$ : saisonaler Effekt

- $$z_k$$ : Fehlerterm



## Multiplikatives Zerlegungsmodell

* saisonale Effekt nimmt mit Trend zu

* gegeben durch:

  

  * $$x_k = m_k \cdot s_k + y_k$$

    

* wenn das Rauschen (Fehlerterm) auch multiplikativ ist, dann ist Logarithmus von $$x_k$$ wieder linear:

  

  * $$log(x_k) = log(m_k) + log(s_k) + log(y_k)$$



## Moving Average

* Einfache Methode Trend $$m_k$$ und saisonalen Effekt $$s_k$$ abzuschätzen
* mittel moving average filter



## Moving Average Filter

* moving average filter der Länge $$p​$$

* definiert durch:

  * Falls $$p \in \N$$ ungerade, dann $$p = 2l + 1​$$

    $$\to$$ gefilterte Folge davon: $$g(x_i) = \frac{1}{p} (x_{i-l} + … + x_{i+l})$$

  * Falls $$p \in \N$$ gerade, dann $$p = 2l$$
    $$\to$$ gefilterte Folge davon: $$g (x_i ) = \frac{1}{p} (x_{i−l} + x_{i −l +1} + ... + x_{i +l −1} + \frac{1}{2} x_{i +l}) $$

* $$p$$ : Fensterbreite / window width

* $$i$$-ter Wert durch Mittelwert der nächsten $$p$$ Nachbarn ersetzt
* da an jedem Zeitpunkt über eine ganze Periode gemittelt wird, verschwinden die saisonalen Effekte $$\to$$ **Trend besser ersichtlich**



## Moving Average Filter anwenden

* `rolling(window=…).mean()`



```python
AirP["Trend"] = AirP["Passengers"].rolling(window=12).mean()

AirP["Passengers"].plot()
AirP["Trend"].plot() 
plt.legend(["Daten","Trend"]) 
plt.show()
```



## Saisonaler additiver Effekt abschätzen

* $$\hat{s}_k = x_k - \hat{m}_k$$
* Daten minus Trend
* `data["Season"] = data["Values"] - data["Trend"]`
* **Saisonale Effekte ersichtlich** ohne Trend



## Durchschnittliche Saisonalität

* Mittelwert der entsprechenden Monate



```python
# AirP[’Season’] wird in eine Matrix umgewandelt # mit den Monaten als Spalten (Jahre als Zeilen)
AirP2 = AirP["Season"].values.reshape((12,12))

# Entlang der Spalten (axis=0) wird der Mittelwert genommen
# nanmean bedeutet, die NaN werden ignoriert
ave = np.nanmean(AirP2,axis=0)

# Der Vektor ave wird verzwölfacht,
# damit er wieder die gleiche Länge hat, wie AirP[’Season’]
AirP["Season_ave"] = np.tile(A=ave, reps=12) 
AirP["Season_ave"].plot()
plt.show()
```



## Restterm

* (Fehlerterm?) 
* Schätzungen von Trend und Saisonalität von ursprünglichen Daten subtrahieren
* Sollte aus möglicherweise korrelierten Zufallsvariablen bestehen
  * ohne Struktur / Periodizität
* $$\hat{r} = x_i - \hat{m}_i - \hat{s_i}$$

<p style="color:#9b0c00">Question: is it the Fehlerterm, and what does it tell me about the data?</p>



## Restterm anwenden

* `seasonal_decompose(data, model="additive", freq=12).plot()`



```python
from statsmodels.tsa.seasonal import seasonal_decompose 

seasonal_decompose(AirP["Passengers"], model="additive", freq=12).plot()
```



## Was ist ein Grund für nichtzufälliges Verhalten eines Restterms (additiv)?

* lineares Zerlegungsmodell stimmt nicht
* entspricht also einem multiplikativen Modell



## Nachteile dieses Zerlegungsverfahrens

* sehr einfach, aber
  * Robustheit gegenüber Ausreissern fehlt
  * Saisonalität konstant über Zeit angenommen
* bessere Lösungen, wie STL-Verfahren