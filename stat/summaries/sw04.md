# 4 | Gesetz der grossen Zahl & Zentraler Grenzwertsatz



## Eigenschaften Linearer Transformationen

* $$E[Y] = E[a + bX] = a + bE[X]$$
* $$Var[Y] = Var[a + bX] = b^2Var[X]​$$
* $$\sigma_Y = |b| \sigma_X$$
* $$q_Y(\alpha) = a + bq_X(\alpha)$$
* Standardisierung:
  - $$\displaystyle f_Y(y) = \frac{1}{b} f_X \left( \frac{y-a}{b} \right)$$



## Unabhängig und i.i.d Annahme

* Wenn Zufallsvariablen $$X_1, …, X_n$$
  * unabhängig
  * alle dieselbe Verteilung,
* dann schreibt man $$X_1, …, X_n \text{ i.i.d.}​$$

* **i**ndependent, **i**dentically **d**istributed



## Augensumme $$S_n$$

* $$S_n = X_1 + X_2 + … + X_n = \sum^n_{i=1} X_i$$
* z.B. Summe der Augenzahlen der geworfenen Würfel
* Bei Simulationsdurchgängen (z.b. 1000 Durchgänge)
  * Wenn Anzahl Summanden 4 Mal so gross
  * Standardabweichung der Summe verdoppelt sich
  * $$\sigma_{S_{40}} = 2 \cdot \sigma_{S_{10}}​$$
  * Je mehr Würfel aufs mal geworfen pro Durchgang, desto breiter die Streuung der Augensumme



## Kennzahlen von $$S_n$$

- $$\displaystyle S_n = X_1 + … + X_n = \sum^n_{i=1} X_i$$
- $$E(S_n) = E(X_1 + X_2 + … + X_n) = \sum^n_{i=1} E(X_i)= n\mu$$
- $$Var(S_n) = n\ Var(X) = Var(X_1 + X_2 + … + X_n) = \sum^n_{i=1} Var(X_i) = n\sigma^2_X$$
- $$\sigma(S_n) = \sqrt{n} \sigma_x​$$



## Mittlere Augenzahl $$\overline{X}_n$$

* $$\overline{X}_n = \frac{X_1 + X_2 + … + X_n}{n} = \frac{1}{n} \sum^n_{i=1} X_i$$
* Arithmetisches Mittel
* z.B. der Durchschnitt der Augenzahlen der geworfenen Würfel
* Bei Simulationsdurchgängen (z.B. 1000 Durchgänge)
  * Wenn Anzahl Summanden 4 Mal so gross
  * Standardabweichung des arithmetischen Mittels halbiert sich
  * $$\sigma_{\overline{X}_{40}} = \frac{1}{2} \cdot \sigma_{\overline{X}_{10}}$$
  * Je mehr Würfel aufs mal geworfen pro Durchgang, desto schmaller die Streuung des arithmetischen Mittels
  * Man ist immer näher am Erwartungswert



## Kennzahlen von $$\overline{X}_n$$

- $$\displaystyle \overline{X}_n = \frac{1}{n} (X_1 + X_2 + … + X_n) = \frac{1}{n} \sum^n_{i=1} X_i = \frac{1}{n} S_n$$
- $$E(\overline{X}_n) = E\left( \frac{X_1 + X_2 + … + X_n}{n}\right) = \frac{1}{n}\sum^n_{i=1} E(X_i) = \frac{1}{n}n\mu =  \mu​$$
- $$Var(\overline{X}_n) = Var \left( \frac{X_1 + X_2 + … + X_n}{n} \right) =  \frac{1}{n^2}\sum^n_{i=1} Var(X_i) = \frac{1}{n^2}n\sigma^2_X =  \frac{\sigma^2_X}{n}$$
- oder auch: $$Var(\overline{X}_n) = \frac{1}{n} (Var(X))$$
  (dann ganz old-school Varianz ausrechnen durch $$n$$)
- $$\sigma(\overline{X}_n) = \frac{\sigma_X}{\sqrt{n}}$$ (Standard-Fehler)



## Standard-Fehler des arithmetischen Mittels

* Standardabweichung von $$X_n$$ heisst Standard-Fehler des arithmetischen Mittels



## Gesetz der grossen Zahlen (GGZ)

- Für $$n$$ sehr gross ist das arithmetische Mittel $$\overline{X}_n$$ sehr nahe am Erwartungswert
- Für $$n \to \infin$$ geht die Streuung gegen null
- Falls $$X_1, …, X_n \text{ i.i.d.}$$
  - $$\overline{X}_n \to \mu$$ für $$n \to \infin$$
- Wenn die Streuung jeder Durchführung null ist, dann ist das arithmetische Mittel aller Durchführungen gleich dem Erwartungswert
- Standardabweichung nimmt mit Faktor $$\frac{1}{\sqrt{n}} \sigma_X$$ ab
- Um Standardfehler zu halbieren, braucht mal viermal so viele Beobachtungen
  - $$\sqrt{n}$$ - Gesetz



## Zentraler Grenzwertsatz

- Falls $$X_1, …, X_n \text{ i.i.d.}$$ mit Erwartungswert $$\mu$$ und Varianz $$\sigma^2$$ dann gilt
  - $$S_n \sim \mathcal{N}(n\mu,n\sigma^2_X )$$
  - $$\overline{X}_n \sim \mathcal{N}(\mu, \frac{\sigma^2_X}{n})$$
  - Binomialverteilung $$\approx$$ Normalverteilung für $$n$$ gross
  - Poissonverteilung $$\approx$$ Normalverteilung für $$\lambda$$ gross
  - Approximation wird meist besser mit grösserem $$n$$
  - Apprimation besser, je normalverteilter die Verteilung von $$X_i$$
- $$S_n$$ ist die Summe von irgendwie-verteilten Zufallsvariablen und ist normalerweise approximiert normalverteilt



## Normalapproximation Binomialverteilung

- Wenn GGZ und Zentraler Grenzwertsatz zutreffen
- Wenn $$X \sim \text{Bin}(n, \pi)$$ gilt
  - $$\pi$$ ist eine Variable (nicht Wert $$\pi$$)
  - $$\mu = E(X) = n\pi$$
  - $$\sigma^2 = Var(X) = n \pi (1-\pi)$$
  - Als Approximation Normalverteilung $$\mathcal{N}(\mu, \sigma^2)​$$ nehmen
- Wahrscheinlichkeit berechnen durch Standardisieren,
  - $$\displaystyle P[X \leq x] \approx \Phi \left( \frac{x - n\pi}{\sqrt{n\pi(1-\pi)}} \right)$$



## Normalapproximation Poissonverteilung

* Wenn GGZ und Zentraler Grenzwertsatz zutreffen
* Wenn $$X \sim Pois(\lambda)$$
  * $$X \sim \text{Pois}(\lambda)$$
  * $$\mu = E[X] = \lambda$$
  * $$\sigma^2 = Var[X] = \lambda$$
  * Als Approximation Normalverteilung $$\mathcal{N}(\mu, \sigma^2)$$ nehmen
* Wahrscheinlichkeit berechnen durch Standardisieren,
  * $$\displaystyle P[X \leq x] \approx \Phi \left( \frac{x - \lambda}{\sqrt{\lambda}} \right)$$



## Fehlerrechnung

* Messungen physikalischer Grössen meist fehlerbehaftet
* Messwerte weichen vom wahren Wert ab
* Unterscheidung
  * systematische Fehler
  * zufällige Fehler



## Systematische Fehler

* Entstehen durch Unvollkommenheit der Messgeräte
* z.B. Funktionsfehler, Eichfehler, Unvollkommenheit der Messverfahren
* Konkrete Beispiele
  * Nullpunktsfehler: Bei Kurzschluss der Eingänge zeigt Voltmeter nicht $$0$$ V an 
  * Bei Pendelversuch wird durch Luft- und Lagerreibung die Schwingung gedämpft, wodurch Frequenz der Schwingung verringert wird
* Sollten vermieden / kleingehalten werden
* Nicht Gegenstand einer Fehlerrechnung



## Zufällige Fehler

* Entstehen vor allem durch Naturgesetze
  * Aufgrund der statistischen Natur von Kernzerfällen
  * Durch Ungeschicklichkeit beim Messen
  * Durch statistisch schwankende äussere / innere Einflüsse (Druck, Temp., …)
* Grösse der zufälligen Fehler durch Standardfehler $$\displaystyle s_{\overline{x}_n}$$ definiert
  * $$\displaystyle s_{\overline{x}_n} = \frac{s_x}{\sqrt{n}}$$ 
  * $$\displaystyle \overline{x}_n \pm s_{\overline{x}_n}$$ (absolute Fehler)
  * $$\displaystyle \overline{x}_n \pm \frac{s_{\overline{x}_n}}{\overline{x}_n} \cdot 100\% ​$$  (relativer Fehler)

